# ğŸ“Š Projeto de Engenharia e AnÃ¡lise de Dados com Docker, Python, Streamlit e PostgreSQL

Este projeto foi desenvolvido com o objetivo de demonstrar conhecimentos prÃ¡ticos em **engenharia de dados** e **anÃ¡lise de dados**, utilizando ferramentas modernas como **Docker**, **Python**, **FastAPI**, **Streamlit** e **PostgreSQL**.

---

## ğŸ›  Tecnologias Utilizadas

- **Python** â€“ desenvolvimento da API e do dashboard
- **FastAPI** â€“ criaÃ§Ã£o de uma API leve e eficiente
- **Streamlit** â€“ construÃ§Ã£o de dashboards interativos
- **PostgreSQL** â€“ banco de dados relacional para persistÃªncia dos dados
- **Docker & Docker Compose** â€“ orquestraÃ§Ã£o dos serviÃ§os em containers isolados
- **VSCode** â€“ IDE para desenvolvimento e organizaÃ§Ã£o do projeto

---

## ğŸ“ Estrutura do Projeto

```text
DockerCompose/
â”œâ”€â”€ api/                        # API em Python com FastAPI
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboard/                  # Dashboard com Streamlit
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ init.sql                    # Script de inicializaÃ§Ã£o do banco PostgreSQL
â”œâ”€â”€ docker-compose.yml          # Arquivo de orquestraÃ§Ã£o Docker
â””â”€â”€ README.md                   # DocumentaÃ§Ã£o do projeto

ğŸš€ Como Executar o Projeto
PrÃ©-requisitos
Docker instalado (Download aqui)

Docker Compose

Passos para executar
bash
Copy
Edit
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/DockerCompose.git
cd DockerCompose

# Suba os containers
docker-compose up --build
Acesso aos serviÃ§os
ğŸ“Š Dashboard (Streamlit): http://localhost:8501

ğŸ§ª API (FastAPI Docs): http://localhost:8000/docs


ğŸ¯ Objetivo do Projeto
Simular um ambiente real de dados usando containers Docker

Construir uma API RESTful para servir dados estruturados

Criar um dashboard interativo com grÃ¡ficos e KPIs

Praticar boas prÃ¡ticas de organizaÃ§Ã£o de projetos de dados

ğŸ§  PossÃ­veis ExtensÃµes
Pipeline de ETL com agendamento

IntegraÃ§Ã£o com ferramentas de orquestraÃ§Ã£o (ex: Airflow)

AdiÃ§Ã£o de autenticaÃ§Ã£o na API e dashboard

ExportaÃ§Ã£o de relatÃ³rios automatizados